import json
import time
import math
import socket
import logging
from urllib import request
from urllib import error

import config
import util

print('daliy fund to db â›½ï¸')


class FundCrawler():
    """
    æŠ“å–æ•°æ® å¹¶ä¿å­˜æœ‰æ•ˆå€¼
    """

    def __init__(self, x, y):
        self.date = x
        self.p_daliyxxx = y
        print('crawl initğŸ‘')
    # åŸºé‡‘ç±»å‹å­—å…¸
    _fund_type1 = config.fundType1
    _fund_type2 = config.fundType2

    # æ•°æ®æ¥å£
    __interface_targeturl = 'http://eid.csrc.gov.cn/fund/disclose/getPublicFundJZInfoMore.do?aoData=%5B%7B%22name%22%3A%22sEcho%22%2C%22value%22%3A1%7D%2C%7B%22name%22%3A%22iColumns%22%2C%22value%22%3A5%7D%2C%7B%22name%22%3A%22sColumns%22%2C%22value%22%3A%22%2C%2C%2C%2C%22%7D%2C%7B%22name%22%3A%22iDisplayStart%22%2C%22value%22%3A{iDisplayStart}%7D%2C%7B%22name%22%3A%22iDisplayLength%22%2C%22value%22%3A20%7D%2C%7B%22name%22%3A%22mDataProp_0%22%2C%22value%22%3A%22fund%22%7D%2C%7B%22name%22%3A%22mDataProp_1%22%2C%22value%22%3A%22fund%22%7D%2C%7B%22name%22%3A%22mDataProp_2%22%2C%22value%22%3A%22fund%22%7D%2C%7B%22name%22%3A%22mDataProp_3%22%2C%22value%22%3A%22fund%22%7D%2C%7B%22name%22%3A%22mDataProp_4%22%2C%22value%22%3A%22valuationDate%22%7D%2C%7B%22name%22%3A%22fundType%22%2C%22value%22%3A%22{fundType}%22%7D%2C%7B%22name%22%3A%22fundCompanyShortName%22%2C%22value%22%3A%22%22%7D%2C%7B%22name%22%3A%22fundCode%22%2C%22value%22%3A%22%22%7D%2C%7B%22name%22%3A%22fundName%22%2C%22value%22%3A%22%22%7D%2C%7B%22name%22%3A%22startDate%22%2C%22value%22%3A%22{startDate}%22%7D%2C%7B%22name%22%3A%22endDate%22%2C%22value%22%3A%22{endDate}%22%7D%5D'
    # æ•°æ®åˆ—è¡¨
    _datalist = []

    def crawl_all(self):
        """
        æŠ“å–æ‰€æœ‰ç±»å‹æ•°æ®
        """
        for key in self._fund_type1:
            logging.warning('å¼€å§‹æŠ“å–%s' % (key))
            # é˜¶æ®µæ€§ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶ä¸­
            self._datalist += self.crawl_type(self._fund_type1, key)
        for key in self._fund_type2:
            logging.warning('å¼€å§‹æŠ“å–%s' % (key))
            self._datalist += self.crawl_type(self._fund_type2, key)

        if len(self._datalist) > 0:
            logging.warning('å¤„ç†å‰ %s  ', len(self._datalist))
            funddatas = util.parse_datalist(self._datalist)
            # ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“
            logging.warning('å¼€å§‹å…¥daliyåº“')
            logging.warning('æ¸…æ´—å %s ', len(funddatas))
            result = self.p_daliyxxx.insert_many(funddatas)
            logging.warning('å…¥åº“å®Œæ¯•! å…±%sæ¡æ•°æ®', len(funddatas))
        else:
            logging.warning('0æ¡æ•°æ®ï¼Œæ²¡æœ‰å…¥åº“')

    def crawl_type(self, type, key):
        """
        æŠ“å–ä¸€ä¸ªç±»å‹æ•°æ®
        """
        datatype = []
        idisplay_start = 0

        while True:
            urldata = self.__interface_targeturl.format(
                iDisplayStart=idisplay_start, fundType=type[key], startDate=self.date, endDate=self.date)

            dataobj = util.fetch_page(logging, urldata)

            # å‡ºç°ç½‘ç»œå¼‚å¸¸åˆ™å¢åŠ é—´éš”é‡æŸ¥
            i = 1
            while dataobj == '':
                i += 1
                if i > 10:
                    time.sleep(5)
                else:
                    time.sleep(2)

                dataobj = util.fetch_page(logging, urldata)

            dataobj = util.parse_data(dataobj)
            if dataobj == '':
                # print('ä¸æ˜¯json')
                logging.warning('ä¸æ˜¯json %s' % (dataobj))
                break

            if idisplay_start == 0:
                # print('å…±%sæ¡ %sé¡µ' % (dataobj['iTotalRecords'], math.ceil(dataobj['iTotalRecords']/20)))
                logging.warning('å…±%sæ¡ %sé¡µ' % (
                    dataobj['iTotalRecords'], math.ceil(dataobj['iTotalRecords']/20)))
            # å‡€å€¼æ•°æ®
            datatype += dataobj['aaData']
            # æ—¶é—´é—´éš”
            time.sleep(0.5)
            idisplay_start += 20

            # æ˜¾ç¤ºè¿›åº¦
            page = int(idisplay_start/20)
            print('.%sé¡µ' % (page), end=' ', flush=True)
            if len(dataobj['aaData']) < 20:
                # print('å…±%sé¡µ' % (page))
                logging.warning('å…±%sé¡µ' % (page))
                break
        return datatype


class Daliy2History():
    """
    å°†daliyè¡¨ä¸­codeå­˜åœ¨äºhistoryè¡¨ä¸­çš„æ•°æ® ä¿å­˜åˆ°historyè¡¨ä¸­
    """

    def __init__(self, x, y, z):
        # print('Daliy2History initğŸ‘')
        self.date = x
        self.p_daliyxxx = y
        self.p_history = z

    def process(self):
        # æŸ¥historyè¡¨ä¸­çš„code
        his_codes = self.p_history.distinct('code')
        logging.warning('his_codes: %s', his_codes)
        daliy = self.p_daliyxxx.find({'code': {'$in': his_codes}})
        daliy_list = list(daliy)
        if len(daliy_list) > 0:
            result = self.p_history.insert_many(daliy_list)
            logging.info('daliyå­˜å…¥å†å²è¡¨å®Œæˆ: %s', daliy_list)
        else:
            logging.info('å½“å‰historyè¡¨æ— æ–°å¢æ•°æ®')


class DaliyXXX2Daliy():
    """
    daliyè¡¨ä»…ä¿å­˜ä¸Šä¸€æ—¥æ•°æ®
    å°†æ¯æ—¥å‡€å€¼æ•°æ® ä¿å­˜åˆ°'daliy'è¡¨ä¸­
    """

    def __init__(self, x, y):
        self.p_daliyxxx = x
        self.p_daliy = y

    def save(self):
        p_daliyxxx = self.p_daliyxxx.find({})
        daliyxxx_list = list(p_daliyxxx)
        # logging.warning('daliyxxx: %s', daliyxxx_list)
        if len(daliyxxx_list) > 0:
            # æ¸…ç©ºdaliyè¡¨æ•°æ®
            self.p_daliy.delete_many({})  # æ¨èdelete_many æ›¿ä»£remove({})
            result = self.p_daliy.insert_many(daliyxxx_list)


if __name__ == '__main__':

    # date = '2021-04-23'  # å‘¨å…­å‘¨æ—¥æ²¡æœ‰æ–°æ•°æ®
    date = util.yesterday()
    # è¿æ¥æ•°æ®åº“
    db = util.connect_db()
    p_daliyxxx = db[config.daliyxxx]  # æŒ‡å®šæ“ä½œçš„é›†åˆ type:collection  daliy20210426
    p_history = db[config.history]

    logfilename = '%s/funddaliy%s.log' % (config.logfileDir, date)
    logging.basicConfig(filename=logfilename,
                        level=logging.DEBUG, format='%(asctime)s %(message)s')
    logging.warning('ğŸ˜Š å¼€å§‹ ğŸ')

    if p_daliyxxx and p_daliyxxx.estimated_document_count() == 0:
        # æŠ“å–daliyæ•°æ®
        d2d = FundCrawler(date, p_daliyxxx)
        logging.warning('å¼€å§‹æŠ“å–[%s]', date)
        d2d.crawl_all()
    else:
        logging.warning('%sè¡¨å·²æœ‰æ•°æ®ï¼Œä¸éœ€è¦é‡å¤æŠ“å–', config.daliyxxx)

    logging.warning('ğŸ˜Šdaliyxxxè¡¨ å®Œæˆ âœ… : %s', config.daliyxxx)
    d2h = Daliy2History(date, p_daliyxxx, p_history)
    d2h.process()
    logging.warning('ğŸ˜Šhistoryè¡¨ å®Œæˆ âœ… : %s', config.history)
    p_daliy = db[config.daliy]
    d2d = DaliyXXX2Daliy(p_daliyxxx, p_daliy)
    d2d.save()
    logging.warning('ğŸ˜Šdaliyè¡¨ å®Œæˆ âœ… : %s', config.daliy)
